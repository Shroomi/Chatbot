{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    This file is used to discuss the importance of\n",
    "    weight initialization.\n",
    "    \n",
    "    There are several ways of weight initialization.\n",
    "    \n",
    "    1. Pre-training\n",
    "    2. Random Initialization\n",
    "    3. Xavier Initialization\n",
    "    4. He Initialization\n",
    "    5. Batch Normalization Layer\n",
    "'''\n",
    "\n",
    "# Pre-training: Use the model which has been trained on task A\n",
    "#               for task B with fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input mean 0.00092 and std 1.00075\n",
      "layer 1: mean -0.00029 and std 0.26390\n",
      "layer 2: mean -0.00007 and std 0.07204\n",
      "layer 3: mean -0.00000 and std 0.01906\n",
      "layer 4: mean 0.00001 and std 0.00485\n",
      "layer 5: mean -0.00000 and std 0.00119\n",
      "layer 6: mean 0.00000 and std 0.00028\n",
      "layer 7: mean -0.00000 and std 0.00006\n",
      "layer 8: mean -0.00000 and std 0.00001\n",
      "layer 9: mean 0.00000 and std 0.00000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1820538d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Initialization\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    data = tf.constant(np.random.randn(2000, 800).astype('float32'))\n",
    "    layer_sizes = [800 - 50 * i for i in range(0,10)]\n",
    "    num_layers = len(layer_sizes)\n",
    "    \n",
    "    fcs = [] # store the output of each layer\n",
    "    for i in range(0, num_layers - 1):\n",
    "        X = data if i == 0 else fcs[i - 1]\n",
    "        node_input = layer_sizes[i]\n",
    "        node_output = layer_sizes[i + 1]\n",
    "        W = tf.Variable(np.random.randn(node_input, node_output).astype\n",
    "                ('float32')) * 0.01 # Random Gaussian/Normal Distribution Initialization for weights\n",
    "        fc = tf.matmul(X, W)\n",
    "        fc = tf.nn.tanh(fc)\n",
    "        fcs.append(fc)\n",
    "        \n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('input mean {0:.5f} and std {1:.5f}'.format(np.mean(data.eval()),\n",
    "                                                      np.std(data.eval())))\n",
    "    \n",
    "    for idx, fc in enumerate(fcs):\n",
    "        print('layer {0}: mean {1:.5f} and std {2:.5f}'.format(idx+1, np.mean(fc.eval()),\n",
    "                                                              np.std(fc.eval())))\n",
    "        \n",
    "    plt.figure()\n",
    "    for idx, fc in enumerate(fcs):\n",
    "        plt.subplot(1, len(fcs), idx+1)\n",
    "        plt.hist(fc.eval().flatten(), 30, range=[-1,1])\n",
    "        plt.xlabel('layer ' + str(idx + 1))\n",
    "        plt.yticks([])\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
